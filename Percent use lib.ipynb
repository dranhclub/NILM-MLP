{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dự đoán phần trăm công suất, sử dụng thư viện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 4)\n",
    "\n",
    "# ----------READ DATA-------------\n",
    "# Power dataframe\n",
    "p_df = pd.read_csv('./data/W.csv',\n",
    "                   names=['time', 'light', 'socket', 'heater', 'aircond1', 'aircond2', 'aircond3', 'indcooker'],\n",
    "                   header=0)\n",
    "# Voltage dataframe\n",
    "u_df = pd.read_csv('./data/V.csv',\n",
    "                   names=['time', 'u'],\n",
    "                   header=0)\n",
    "# Current dataframe\n",
    "i_df = pd.read_csv('./data/A.csv',\n",
    "                   names=['time', 'light', 'socket', 'heater', 'aircond1', 'aircond2', 'aircond3', 'indcooker'],\n",
    "                   header=0)\n",
    "# Power factor dataframe\n",
    "pf_df = pd.read_csv('./data/cosphi.csv',\n",
    "                    names=['time', 'light', 'socket', 'heater', 'aircond1', 'aircond2', 'aircond3', 'indcooker'],\n",
    "                    header=0)\n",
    "\n",
    "# Reactive power dataframe\n",
    "q_df = pd.DataFrame()\n",
    "q_df['time'] = p_df['time']\n",
    "column_names = ['light', 'socket', 'heater', 'aircond1', 'aircond2', 'aircond3', 'indcooker']\n",
    "\n",
    "# Calculate reactive power using P and cosphi\n",
    "for col_name in column_names:\n",
    "    q_df[col_name] = np.tan(np.arccos(pf_df[col_name])) * p_df[col_name]\n",
    "\n",
    "select_device = ['heater', 'indcooker']\n",
    "\n",
    "p_sum = p_df[select_device].sum(axis=1).to_numpy()\n",
    "q_sum = q_df[select_device].sum(axis=1).to_numpy()\n",
    "u_sum = u_df['u'].to_numpy()  # không cần tính tổng U, nhưng cứ đặt là u_sum cho đồng nhất\n",
    "i_sum = i_df[select_device].sum(axis=1).to_numpy()\n",
    "\n",
    "plt.title(\"Công suất P theo thời gian\")\n",
    "plt.plot(p_sum)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "light    : chiếu sáng  \n",
    "socket   : ổ cắm phòng khách + bếp + ngủ  \n",
    "heater   : bình nóng lạnh  \n",
    "aircond1 : điều hoà 1 & 2  \n",
    "aircond2 : điều hoà 3  \n",
    "aircond3 : điều hoà phòng khách  \n",
    "indcooker: bếp từ  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chuẩn bị tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data point = 31680\n",
      "X.shape=(31680, 4)\n",
      "y.shape=(31680, 2)\n",
      "X[0:10]=array([[0.231     , 0.25      , 0.001     , 0.04999   ],\n",
      "       [0.23      , 0.25      , 0.0035    , 0.05822824],\n",
      "       [0.23      , 0.25      , 0.006     , 0.05969925],\n",
      "       [0.23      , 0.25      , 0.0035    , 0.05822824],\n",
      "       [0.23      , 0.25      , 0.001     , 0.04999   ],\n",
      "       [0.23      , 0.25      , 0.001     , 0.04999   ],\n",
      "       [0.23      , 0.25      , 0.001     , 0.04999   ],\n",
      "       [0.23      , 0.25      , 0.004     , 0.05700269],\n",
      "       [0.23      , 0.25      , 0.005     , 0.05861064],\n",
      "       [0.23      , 0.25      , 0.002     , 0.05710785]])\n",
      "y[0:10]=array([[0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "label = []\n",
    "for t in range(0, len(p_sum)):\n",
    "    data.append([u_sum[t] / 1000, i_sum[t] , p_sum[t] / 1000, q_sum[t] / 1000])\n",
    "    percent = []\n",
    "    for j, device_name in enumerate(select_device):\n",
    "        if p_sum[t] == 0:\n",
    "            percent.append(0)\n",
    "        else:\n",
    "            percent.append(p_df[device_name].iloc[t] / p_sum[t])\n",
    "    label.append(percent)\n",
    "        \n",
    "print(\"num data point =\", len(data))\n",
    "\n",
    "\n",
    "X = np.array(data)\n",
    "y = np.array(label)\n",
    "print(f'{X.shape=}')\n",
    "print(f'{y.shape=}')\n",
    "print(f'{X[0:10]=}')\n",
    "print(f'{y[0:10]=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 82310022232861917184.00000000\n",
      "Validation score: -4.093519\n",
      "Iteration 2, loss = 72549318073658204160.00000000\n",
      "Validation score: -4.098439\n",
      "Iteration 3, loss = 61511667207848558592.00000000\n",
      "Validation score: -4.051695\n",
      "Iteration 4, loss = 55485994093058154496.00000000\n",
      "Validation score: -4.041788\n",
      "Iteration 5, loss = 46195651490870640640.00000000\n",
      "Validation score: -4.013399\n",
      "Iteration 6, loss = 38099816113494220800.00000000\n",
      "Validation score: -3.937036\n",
      "Iteration 7, loss = 35055879620379529216.00000000\n",
      "Validation score: -3.998214\n",
      "Iteration 8, loss = 27415259900588998656.00000000\n",
      "Validation score: -3.935621\n",
      "Iteration 9, loss = 25087602216127193088.00000000\n",
      "Validation score: -3.932647\n",
      "Iteration 10, loss = 20160148523890946048.00000000\n",
      "Validation score: -3.839623\n",
      "Iteration 11, loss = 15805194273819852800.00000000\n",
      "Validation score: -3.619806\n",
      "Iteration 12, loss = 13466588037745596416.00000000\n",
      "Validation score: -3.381972\n",
      "Iteration 13, loss = 11323309928404150272.00000000\n",
      "Validation score: -3.113989\n",
      "Iteration 14, loss = 10214421625497344000.00000000\n",
      "Validation score: -2.882589\n",
      "Iteration 15, loss = 7705465660279138304.00000000\n",
      "Validation score: -2.661767\n",
      "Iteration 16, loss = 7091640374984999936.00000000\n",
      "Validation score: -2.712643\n",
      "Iteration 17, loss = 5537142014686647296.00000000\n",
      "Validation score: -2.641267\n",
      "Iteration 18, loss = 3906404049801087488.00000000\n",
      "Validation score: -2.429643\n",
      "Iteration 19, loss = 3599178159492293120.00000000\n",
      "Validation score: -2.284466\n",
      "Iteration 20, loss = 2667015257283636736.00000000\n",
      "Validation score: -2.077784\n",
      "Iteration 21, loss = 2247131145861477376.00000000\n",
      "Validation score: -1.861745\n",
      "Iteration 22, loss = 1673997359546624256.00000000\n",
      "Validation score: -1.614331\n",
      "Iteration 23, loss = 1010959352705956608.00000000\n",
      "Validation score: -1.363570\n",
      "Iteration 24, loss = 655169173119358976.00000000\n",
      "Validation score: -1.111097\n",
      "Iteration 25, loss = 556206881708940352.00000000\n",
      "Validation score: -0.760064\n",
      "Iteration 26, loss = 315077292476300160.00000000\n",
      "Validation score: -0.374346\n",
      "Iteration 27, loss = 159003872312549568.00000000\n",
      "Validation score: -0.099574\n",
      "Iteration 28, loss = 102853426558977840.00000000\n",
      "Validation score: 0.060846\n",
      "Iteration 29, loss = 43391212254032104.00000000\n",
      "Validation score: 0.151667\n",
      "Iteration 30, loss = 11945585026660526.00000000\n",
      "Validation score: 0.198829\n",
      "Iteration 31, loss = 5153775034919405.00000000\n",
      "Validation score: 0.223855\n",
      "Iteration 32, loss = 1422930549256942.50000000\n",
      "Validation score: 0.242677\n",
      "Iteration 33, loss = 690724256585394.37500000\n",
      "Validation score: 0.250512\n",
      "Iteration 34, loss = 51670072520379.94531250\n",
      "Validation score: 0.244077\n",
      "Iteration 35, loss = 128114573336631.34375000\n",
      "Validation score: 0.246790\n",
      "Iteration 36, loss = 160415295131651.06250000\n",
      "Validation score: 0.258265\n",
      "Iteration 37, loss = 145083724221782.43750000\n",
      "Validation score: 0.272371\n",
      "Iteration 38, loss = 109981820682083.14062500\n",
      "Validation score: 0.285139\n",
      "Iteration 39, loss = 76729880140537.31250000\n",
      "Validation score: 0.296370\n",
      "Iteration 40, loss = 46945740249692.36718750\n",
      "Validation score: 0.306134\n",
      "Iteration 41, loss = 27774126562246.09765625\n",
      "Validation score: 0.314658\n",
      "Iteration 42, loss = 7157846430401.68359375\n",
      "Validation score: 0.321604\n",
      "Iteration 43, loss = 1434827772817.68554688\n",
      "Validation score: 0.327698\n",
      "Iteration 44, loss = 341840484094.41870117\n",
      "Validation score: 0.333043\n",
      "Iteration 45, loss = 44325383766.17330933\n",
      "Validation score: 0.337728\n",
      "Iteration 46, loss = 208364567696.91265869\n",
      "Validation score: 0.341746\n",
      "Iteration 47, loss = 272982555911.74343872\n",
      "Validation score: 0.345416\n",
      "Iteration 48, loss = 251588096737.76535034\n",
      "Validation score: 0.348922\n",
      "Iteration 49, loss = 107066750934.93339539\n",
      "Validation score: 0.352018\n",
      "Iteration 50, loss = 39862255709.32228851\n",
      "Validation score: 0.354949\n",
      "Iteration 51, loss = 21465687920.65527725\n",
      "Validation score: 0.357558\n",
      "Iteration 52, loss = 6845915243.93437195\n",
      "Validation score: 0.359891\n",
      "Iteration 53, loss = 1927502139.87794018\n",
      "Validation score: 0.361964\n",
      "Iteration 54, loss = 400060088.33982855\n",
      "Validation score: 0.363730\n",
      "Iteration 55, loss = 849539644.66527426\n",
      "Validation score: 0.365292\n",
      "Iteration 56, loss = 611808729.16369009\n",
      "Validation score: 0.366841\n",
      "Iteration 57, loss = 308535643.78669786\n",
      "Validation score: 0.368296\n",
      "Iteration 58, loss = 173053543.23804522\n",
      "Validation score: 0.369610\n",
      "Iteration 59, loss = 98356163.04297139\n",
      "Validation score: 0.370702\n",
      "Iteration 60, loss = 38996128.34911211\n",
      "Validation score: 0.371928\n",
      "Iteration 61, loss = 13870510.64601934\n",
      "Validation score: 0.373115\n",
      "Iteration 62, loss = 10778067.80293110\n",
      "Validation score: 0.374118\n",
      "Iteration 63, loss = 8651288.40635832\n",
      "Validation score: 0.375164\n",
      "Iteration 64, loss = 7508793.55347243\n",
      "Validation score: 0.376149\n",
      "Iteration 65, loss = 3589952.03268537\n",
      "Validation score: 0.377120\n",
      "Iteration 66, loss = 945360.49507639\n",
      "Validation score: 0.378016\n",
      "Iteration 67, loss = 310121.19678152\n",
      "Validation score: 0.378927\n",
      "Iteration 68, loss = 400019.14497561\n",
      "Validation score: 0.379736\n",
      "Iteration 69, loss = 225513.18420270\n",
      "Validation score: 0.380669\n",
      "Iteration 70, loss = 5152122276208808.00000000\n",
      "Validation score: 0.366342\n",
      "Iteration 71, loss = 279669351762288.78125000\n",
      "Validation score: 0.328481\n",
      "Iteration 72, loss = 291493448751078.87500000\n",
      "Validation score: 0.318831\n",
      "Iteration 73, loss = 196977484980351.68750000\n",
      "Validation score: 0.313796\n",
      "Iteration 74, loss = 132880441205456.57812500\n",
      "Validation score: 0.304811\n",
      "Iteration 75, loss = 61742794256878.14843750\n",
      "Validation score: 0.296371\n",
      "Iteration 76, loss = 8846613535038.62109375\n",
      "Validation score: 0.297154\n",
      "Iteration 77, loss = 1712000468198.73828125\n",
      "Validation score: 0.297933\n",
      "Iteration 78, loss = 1151370363435.06860352\n",
      "Validation score: 0.296285\n",
      "Iteration 79, loss = 1264761869435.57177734\n",
      "Validation score: 0.297417\n",
      "Iteration 80, loss = 1443889028527.23876953\n",
      "Validation score: 0.296896\n",
      "Iteration 81, loss = 1129421959479.89355469\n",
      "Validation score: 0.297072\n",
      "Iteration 82, loss = 281083104340.59008789\n",
      "Validation score: 0.297107\n",
      "Iteration 83, loss = 70552190232.12556458\n",
      "Validation score: 0.297273\n",
      "Iteration 84, loss = 11891197627.32758331\n",
      "Validation score: 0.297723\n",
      "Iteration 85, loss = 3479846761.31235981\n",
      "Validation score: 0.297470\n",
      "Iteration 86, loss = 12447564947.95922470\n",
      "Validation score: 0.298090\n",
      "Iteration 87, loss = 17138243837.72190094\n",
      "Validation score: 0.297955\n",
      "Iteration 88, loss = 12584688391.47160530\n",
      "Validation score: 0.298437\n",
      "Iteration 89, loss = 547598918121655.75000000\n",
      "Validation score: 0.294810\n",
      "Iteration 90, loss = 81941151622810.48437500\n",
      "Validation score: 0.287656\n",
      "Iteration 91, loss = 136613310427798.54687500\n",
      "Validation score: 0.284711\n",
      "Iteration 92, loss = 51366053577410.12500000\n",
      "Validation score: 0.285549\n",
      "Iteration 93, loss = 15798140425715.91406250\n",
      "Validation score: 0.286924\n",
      "Iteration 94, loss = 3493932207727.83007812\n",
      "Validation score: 0.287873\n",
      "Iteration 95, loss = 21364067772796.15625000\n",
      "Validation score: 0.288600\n",
      "Iteration 96, loss = 13837384620835.70898438\n",
      "Validation score: 0.289020\n",
      "Iteration 97, loss = 648402157240.28967285\n",
      "Validation score: 0.288873\n",
      "Iteration 98, loss = 109756443385.00712585\n",
      "Validation score: 0.289110\n",
      "Iteration 99, loss = 1287310052124.13525391\n",
      "Validation score: 0.289565\n",
      "Iteration 100, loss = 880135390024.59008789\n",
      "Validation score: 0.289687\n",
      "Iteration 101, loss = 414392328977.46478271\n",
      "Validation score: 0.289752\n",
      "Iteration 102, loss = 217210936247.28268433\n",
      "Validation score: 0.290293\n",
      "Iteration 103, loss = 435559480770.96179199\n",
      "Validation score: 0.290337\n",
      "Iteration 104, loss = 93252989408.53321838\n",
      "Validation score: 0.290677\n",
      "Iteration 105, loss = 10663103192.11724281\n",
      "Validation score: 0.290980\n",
      "Iteration 106, loss = 27165747470.90458679\n",
      "Validation score: 0.291213\n",
      "Iteration 107, loss = 48899917369.06396484\n",
      "Validation score: 0.291425\n",
      "Iteration 108, loss = 9671287812.63928223\n",
      "Validation score: 0.291648\n",
      "Iteration 109, loss = 61416452.96580515\n",
      "Validation score: 0.292079\n",
      "Iteration 110, loss = 676706142.86216617\n",
      "Validation score: 0.291915\n",
      "Iteration 111, loss = 6139682258.02873135\n",
      "Validation score: 0.292438\n",
      "Iteration 112, loss = 3100811945.95436144\n",
      "Validation score: 0.292552\n",
      "Iteration 113, loss = 780023.02053212\n",
      "Validation score: 0.292824\n",
      "Iteration 114, loss = 283629469.52782738\n",
      "Validation score: 0.292939\n",
      "Iteration 115, loss = 381265407.63456750\n",
      "Validation score: 0.293214\n",
      "Iteration 116, loss = 85399380.15793137\n",
      "Validation score: 0.293478\n",
      "Iteration 117, loss = 2440571.15984231\n",
      "Validation score: 0.293747\n",
      "Iteration 118, loss = 11936003.91616609\n",
      "Validation score: 0.293922\n",
      "Iteration 119, loss = 15830780.48389015\n",
      "Validation score: 0.294103\n",
      "Iteration 120, loss = 2997137.53899600\n",
      "Validation score: 0.294351\n",
      "Iteration 121, loss = 109132.88651283\n",
      "Validation score: 0.294731\n",
      "Iteration 122, loss = 334229.97036442\n",
      "Validation score: 0.294895\n",
      "Iteration 123, loss = 813908.75075641\n",
      "Validation score: 0.295068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 124, loss = 197053.32052448\n",
      "Validation score: 0.295401\n",
      "Iteration 125, loss = 68016.59492982\n",
      "Validation score: 0.295818\n",
      "Iteration 126, loss = 211279.43950857\n",
      "Validation score: 0.295904\n",
      "Iteration 127, loss = 180391.09323261\n",
      "Validation score: 0.296217\n",
      "Iteration 128, loss = 11800.80903722\n",
      "Validation score: 0.296366\n",
      "Iteration 129, loss = 31809.15953712\n",
      "Validation score: 0.296874\n",
      "Iteration 130, loss = 29475.07459173\n",
      "Validation score: 0.296862\n",
      "Iteration 131, loss = 7435.28542103\n",
      "Validation score: 0.297242\n",
      "Iteration 132, loss = 15108.87778660\n",
      "Validation score: 0.297606\n",
      "Iteration 133, loss = 9577.21824129\n",
      "Validation score: 0.297740\n",
      "Iteration 134, loss = 974.68040955\n",
      "Validation score: 0.298055\n",
      "Iteration 135, loss = 7164.02380064\n",
      "Validation score: 0.298364\n",
      "Iteration 136, loss = 1743.72145247\n",
      "Validation score: 0.298709\n",
      "Iteration 137, loss = 38.56421858\n",
      "Validation score: 0.298952\n",
      "Iteration 138, loss = 1218.99007540\n",
      "Validation score: 0.299206\n",
      "Iteration 139, loss = 811.44600583\n",
      "Validation score: 0.299504\n",
      "Iteration 140, loss = 52.02524052\n",
      "Validation score: 0.299710\n",
      "Iteration 141, loss = 20.25542354\n",
      "Validation score: 0.300050\n",
      "Iteration 142, loss = 124.44959801\n",
      "Validation score: 0.300388\n",
      "Iteration 143, loss = 64.80979536\n",
      "Validation score: 0.300579\n",
      "Iteration 144, loss = 0.26443589\n",
      "Validation score: 0.301083\n",
      "Iteration 145, loss = 6.59139922\n",
      "Validation score: 0.301235\n",
      "Iteration 146, loss = 6.30860004\n",
      "Validation score: 0.301520\n",
      "Iteration 147, loss = 0.48145435\n",
      "Validation score: 0.302199\n",
      "Iteration 148, loss = 0.07537358\n",
      "Validation score: 0.302283\n",
      "Iteration 149, loss = 1.92495225\n",
      "Validation score: 0.302933\n",
      "Iteration 150, loss = 1.03766395\n",
      "Validation score: 0.302887\n",
      "Iteration 151, loss = 0.10796746\n",
      "Validation score: 0.303555\n",
      "Iteration 152, loss = 1.03770954\n",
      "Validation score: 0.303763\n",
      "Iteration 153, loss = 0.47863540\n",
      "Validation score: 0.303855\n",
      "Iteration 154, loss = 0.06043974\n",
      "Validation score: 0.304320\n",
      "Iteration 155, loss = 0.14134033\n",
      "Validation score: 0.304844\n",
      "Iteration 156, loss = 0.08339623\n",
      "Validation score: 0.304922\n",
      "Iteration 157, loss = 0.05049397\n",
      "Validation score: 0.305462\n",
      "Iteration 158, loss = 0.05511690\n",
      "Validation score: 0.305894\n",
      "Iteration 159, loss = 0.07891912\n",
      "Validation score: 0.306149\n",
      "Iteration 160, loss = 0.05168594\n",
      "Validation score: 0.306610\n",
      "Iteration 161, loss = 0.04994169\n",
      "Validation score: 0.307175\n",
      "Iteration 162, loss = 0.06321073\n",
      "Validation score: 0.307461\n",
      "Iteration 163, loss = 0.05397361\n",
      "Validation score: 0.307887\n",
      "Iteration 164, loss = 0.04986650\n",
      "Validation score: 0.308403\n",
      "Iteration 165, loss = 0.05063808\n",
      "Validation score: 0.308773\n",
      "Iteration 166, loss = 0.05101004\n",
      "Validation score: 0.309204\n",
      "Iteration 167, loss = 0.04991866\n",
      "Validation score: 0.309660\n",
      "Iteration 168, loss = 0.05027014\n",
      "Validation score: 0.309823\n",
      "Iteration 169, loss = 0.05020498\n",
      "Validation score: 0.310606\n",
      "Iteration 170, loss = 0.04954558\n",
      "Validation score: 0.311084\n",
      "Iteration 171, loss = 0.04958610\n",
      "Validation score: 0.311077\n",
      "Iteration 172, loss = 0.04946466\n",
      "Validation score: 0.312061\n",
      "Iteration 173, loss = 0.04940505\n",
      "Validation score: 0.312162\n",
      "Iteration 174, loss = 0.04940485\n",
      "Validation score: 0.312717\n",
      "Iteration 175, loss = 0.04933388\n",
      "Validation score: 0.313303\n",
      "Iteration 176, loss = 0.04926441\n",
      "Validation score: 0.313783\n",
      "Iteration 177, loss = 0.04923937\n",
      "Validation score: 0.314115\n",
      "Iteration 178, loss = 0.04917279\n",
      "Validation score: 0.314903\n",
      "Iteration 179, loss = 0.04912111\n",
      "Validation score: 0.315196\n",
      "Iteration 180, loss = 0.04907440\n",
      "Validation score: 0.315826\n",
      "Iteration 181, loss = 0.04901506\n",
      "Validation score: 0.316473\n",
      "Iteration 182, loss = 0.04896316\n",
      "Validation score: 0.316962\n",
      "Iteration 183, loss = 0.04891148\n",
      "Validation score: 0.317705\n",
      "Iteration 184, loss = 0.04885752\n",
      "Validation score: 0.318023\n",
      "Iteration 185, loss = 0.04880307\n",
      "Validation score: 0.318911\n",
      "Iteration 186, loss = 0.04874851\n",
      "Validation score: 0.319332\n",
      "Iteration 187, loss = 0.04869230\n",
      "Validation score: 0.319881\n",
      "Iteration 188, loss = 0.04863640\n",
      "Validation score: 0.320563\n",
      "Iteration 189, loss = 0.04857917\n",
      "Validation score: 0.321268\n",
      "Iteration 190, loss = 0.04852105\n",
      "Validation score: 0.321646\n",
      "Iteration 191, loss = 0.04846257\n",
      "Validation score: 0.322479\n",
      "Iteration 192, loss = 0.04840292\n",
      "Validation score: 0.323187\n",
      "Iteration 193, loss = 0.04834256\n",
      "Validation score: 0.323605\n",
      "Iteration 194, loss = 0.04828227\n",
      "Validation score: 0.324462\n",
      "Iteration 195, loss = 0.04821990\n",
      "Validation score: 0.325269\n",
      "Iteration 196, loss = 0.04815800\n",
      "Validation score: 0.325636\n",
      "Iteration 197, loss = 0.04809612\n",
      "Validation score: 0.326738\n",
      "Iteration 198, loss = 0.04803201\n",
      "Validation score: 0.326849\n",
      "Iteration 199, loss = 0.04796436\n",
      "Validation score: 0.328071\n",
      "Iteration 200, loss = 0.04789847\n",
      "Validation score: 0.328307\n",
      "Iteration 201, loss = 0.04783145\n",
      "Validation score: 0.329219\n",
      "Iteration 202, loss = 0.04776324\n",
      "Validation score: 0.329792\n",
      "Iteration 203, loss = 0.04769457\n",
      "Validation score: 0.330589\n",
      "Iteration 204, loss = 0.04762476\n",
      "Validation score: 0.331350\n",
      "Iteration 205, loss = 0.04755502\n",
      "Validation score: 0.332264\n",
      "Iteration 206, loss = 0.04748341\n",
      "Validation score: 0.333037\n",
      "Iteration 207, loss = 0.04741080\n",
      "Validation score: 0.333749\n",
      "Iteration 208, loss = 0.04733787\n",
      "Validation score: 0.334511\n",
      "Iteration 209, loss = 0.04726401\n",
      "Validation score: 0.335253\n",
      "Iteration 210, loss = 0.04718903\n",
      "Validation score: 0.336074\n",
      "Iteration 211, loss = 0.04711331\n",
      "Validation score: 0.336953\n",
      "Iteration 212, loss = 0.04703651\n",
      "Validation score: 0.337655\n",
      "Iteration 213, loss = 0.04695879\n",
      "Validation score: 0.338446\n",
      "Iteration 214, loss = 0.04687982\n",
      "Validation score: 0.339480\n",
      "Iteration 215, loss = 0.04680012\n",
      "Validation score: 0.340211\n",
      "Iteration 216, loss = 0.04671973\n",
      "Validation score: 0.341133\n",
      "Iteration 217, loss = 0.04663779\n",
      "Validation score: 0.341845\n",
      "Iteration 218, loss = 0.04655541\n",
      "Validation score: 0.342902\n",
      "Iteration 219, loss = 0.04647237\n",
      "Validation score: 0.343773\n",
      "Iteration 220, loss = 0.04638784\n",
      "Validation score: 0.344686\n",
      "Iteration 221, loss = 0.04630281\n",
      "Validation score: 0.345747\n",
      "Iteration 222, loss = 0.04621593\n",
      "Validation score: 0.346291\n",
      "Iteration 223, loss = 0.04612867\n",
      "Validation score: 0.347633\n",
      "Iteration 224, loss = 0.04604034\n",
      "Validation score: 0.348237\n",
      "Iteration 225, loss = 0.04595187\n",
      "Validation score: 0.349377\n",
      "Iteration 226, loss = 0.04586132\n",
      "Validation score: 0.350390\n",
      "Iteration 227, loss = 0.04576943\n",
      "Validation score: 0.351185\n",
      "Iteration 228, loss = 0.04567700\n",
      "Validation score: 0.352411\n",
      "Iteration 229, loss = 0.04558384\n",
      "Validation score: 0.353222\n",
      "Iteration 230, loss = 0.04549055\n",
      "Validation score: 0.354106\n",
      "Iteration 231, loss = 0.04539380\n",
      "Validation score: 0.355270\n",
      "Iteration 232, loss = 0.04529729\n",
      "Validation score: 0.356300\n",
      "Iteration 233, loss = 0.04520001\n",
      "Validation score: 0.357264\n",
      "Iteration 234, loss = 0.04510222\n",
      "Validation score: 0.358338\n",
      "Iteration 235, loss = 0.04500270\n",
      "Validation score: 0.359600\n",
      "Iteration 236, loss = 0.04490180\n",
      "Validation score: 0.360423\n",
      "Iteration 237, loss = 0.04479970\n",
      "Validation score: 0.361743\n",
      "Iteration 238, loss = 0.04469912\n",
      "Validation score: 0.362817\n",
      "Iteration 239, loss = 0.04459469\n",
      "Validation score: 0.363736\n",
      "Iteration 240, loss = 0.04448944\n",
      "Validation score: 0.365175\n",
      "Iteration 241, loss = 0.04438513\n",
      "Validation score: 0.365866\n",
      "Iteration 242, loss = 0.04427655\n",
      "Validation score: 0.367359\n",
      "Iteration 243, loss = 0.04416942\n",
      "Validation score: 0.368283\n",
      "Iteration 244, loss = 0.04406125\n",
      "Validation score: 0.369651\n",
      "Iteration 245, loss = 0.04395087\n",
      "Validation score: 0.370784\n",
      "Iteration 246, loss = 0.04384028\n",
      "Validation score: 0.371779\n",
      "Iteration 247, loss = 0.04372841\n",
      "Validation score: 0.373325\n",
      "Iteration 248, loss = 0.04361532\n",
      "Validation score: 0.374200\n",
      "Iteration 249, loss = 0.04350219\n",
      "Validation score: 0.375781\n",
      "Iteration 250, loss = 0.04338705\n",
      "Validation score: 0.376704\n",
      "Iteration 251, loss = 0.04327072\n",
      "Validation score: 0.378037\n",
      "Iteration 252, loss = 0.04315370\n",
      "Validation score: 0.379279\n",
      "Iteration 253, loss = 0.04303660\n",
      "Validation score: 0.380475\n",
      "Iteration 254, loss = 0.04291759\n",
      "Validation score: 0.381704\n",
      "Iteration 255, loss = 0.04279782\n",
      "Validation score: 0.383199\n",
      "Iteration 256, loss = 0.04267580\n",
      "Validation score: 0.384336\n",
      "Iteration 257, loss = 0.04255498\n",
      "Validation score: 0.385717\n",
      "Iteration 258, loss = 0.04243108\n",
      "Validation score: 0.386987\n",
      "Iteration 259, loss = 0.04230701\n",
      "Validation score: 0.388545\n",
      "Iteration 260, loss = 0.04218362\n",
      "Validation score: 0.389461\n",
      "Iteration 261, loss = 0.04205718\n",
      "Validation score: 0.391208\n",
      "Iteration 262, loss = 0.04193040\n",
      "Validation score: 0.392299\n",
      "Iteration 263, loss = 0.04180306\n",
      "Validation score: 0.393705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 264, loss = 0.04167360\n",
      "Validation score: 0.395216\n",
      "Iteration 265, loss = 0.04154343\n",
      "Validation score: 0.396290\n",
      "Iteration 266, loss = 0.04141384\n",
      "Validation score: 0.397901\n",
      "Iteration 267, loss = 0.04128182\n",
      "Validation score: 0.399283\n",
      "Iteration 268, loss = 0.04114923\n",
      "Validation score: 0.400682\n",
      "Iteration 269, loss = 0.04101495\n",
      "Validation score: 0.402230\n",
      "Iteration 270, loss = 0.04088155\n",
      "Validation score: 0.403471\n",
      "Iteration 271, loss = 0.04074568\n",
      "Validation score: 0.405135\n",
      "Iteration 272, loss = 0.04060948\n",
      "Validation score: 0.406360\n",
      "Iteration 273, loss = 0.04047282\n",
      "Validation score: 0.408071\n",
      "Iteration 274, loss = 0.04033471\n",
      "Validation score: 0.409305\n",
      "Iteration 275, loss = 0.04019618\n",
      "Validation score: 0.411044\n",
      "Iteration 276, loss = 0.04005622\n",
      "Validation score: 0.412247\n",
      "Iteration 277, loss = 0.03991615\n",
      "Validation score: 0.414240\n",
      "Iteration 278, loss = 0.03977445\n",
      "Validation score: 0.414995\n",
      "Iteration 279, loss = 0.03963146\n",
      "Validation score: 0.417103\n",
      "Iteration 280, loss = 0.03948779\n",
      "Validation score: 0.418149\n",
      "Iteration 281, loss = 0.03934438\n",
      "Validation score: 0.420228\n",
      "Iteration 282, loss = 0.03920147\n",
      "Validation score: 0.421562\n",
      "Iteration 283, loss = 0.03905538\n",
      "Validation score: 0.423246\n",
      "Iteration 284, loss = 0.03890789\n",
      "Validation score: 0.424851\n",
      "Iteration 285, loss = 0.03875997\n",
      "Validation score: 0.426294\n",
      "Iteration 286, loss = 0.03861155\n",
      "Validation score: 0.428017\n",
      "Iteration 287, loss = 0.03846234\n",
      "Validation score: 0.429418\n",
      "Iteration 288, loss = 0.03831349\n",
      "Validation score: 0.431142\n",
      "Iteration 289, loss = 0.03816315\n",
      "Validation score: 0.432595\n",
      "Iteration 290, loss = 0.03801150\n",
      "Validation score: 0.434381\n",
      "Iteration 291, loss = 0.03785993\n",
      "Validation score: 0.435767\n",
      "Iteration 292, loss = 0.03770802\n",
      "Validation score: 0.437576\n",
      "Iteration 293, loss = 0.03755471\n",
      "Validation score: 0.439154\n",
      "Iteration 294, loss = 0.03740197\n",
      "Validation score: 0.440805\n",
      "Iteration 295, loss = 0.03724747\n",
      "Validation score: 0.442417\n",
      "Iteration 296, loss = 0.03709277\n",
      "Validation score: 0.444152\n",
      "Iteration 297, loss = 0.03693645\n",
      "Validation score: 0.445907\n",
      "Iteration 298, loss = 0.03678040\n",
      "Validation score: 0.447607\n",
      "Iteration 299, loss = 0.03662303\n",
      "Validation score: 0.449436\n",
      "Iteration 300, loss = 0.03646574\n",
      "Validation score: 0.451119\n",
      "Iteration 301, loss = 0.03630758\n",
      "Validation score: 0.452748\n",
      "Iteration 302, loss = 0.03614859\n",
      "Validation score: 0.454556\n",
      "Iteration 303, loss = 0.03598941\n",
      "Validation score: 0.456279\n",
      "Iteration 304, loss = 0.03582944\n",
      "Validation score: 0.457900\n",
      "Iteration 305, loss = 0.03566883\n",
      "Validation score: 0.459795\n",
      "Iteration 306, loss = 0.03550793\n",
      "Validation score: 0.461568\n",
      "Iteration 307, loss = 0.03534640\n",
      "Validation score: 0.463203\n",
      "Iteration 308, loss = 0.03518472\n",
      "Validation score: 0.465081\n",
      "Iteration 309, loss = 0.03502340\n",
      "Validation score: 0.466937\n",
      "Iteration 310, loss = 0.03486207\n",
      "Validation score: 0.468341\n",
      "Iteration 311, loss = 0.03469781\n",
      "Validation score: 0.470473\n",
      "Iteration 312, loss = 0.03453269\n",
      "Validation score: 0.472217\n",
      "Iteration 313, loss = 0.03436979\n",
      "Validation score: 0.473948\n",
      "Iteration 314, loss = 0.03420505\n",
      "Validation score: 0.475872\n",
      "Iteration 315, loss = 0.03404045\n",
      "Validation score: 0.477637\n",
      "Iteration 316, loss = 0.03387584\n",
      "Validation score: 0.479389\n",
      "Iteration 317, loss = 0.03371027\n",
      "Validation score: 0.481156\n",
      "Iteration 318, loss = 0.03354483\n",
      "Validation score: 0.482968\n",
      "Iteration 319, loss = 0.03337911\n",
      "Validation score: 0.484816\n",
      "Iteration 320, loss = 0.03321302\n",
      "Validation score: 0.486590\n",
      "Iteration 321, loss = 0.03304549\n",
      "Validation score: 0.488428\n",
      "Iteration 322, loss = 0.03287794\n",
      "Validation score: 0.490286\n",
      "Iteration 323, loss = 0.03271108\n",
      "Validation score: 0.492110\n",
      "Iteration 324, loss = 0.03254293\n",
      "Validation score: 0.493906\n",
      "Iteration 325, loss = 0.03237658\n",
      "Validation score: 0.495888\n",
      "Iteration 326, loss = 0.03220785\n",
      "Validation score: 0.497665\n",
      "Iteration 327, loss = 0.03203976\n",
      "Validation score: 0.499411\n",
      "Iteration 328, loss = 0.03187276\n",
      "Validation score: 0.501452\n",
      "Iteration 329, loss = 0.03170534\n",
      "Validation score: 0.503090\n",
      "Iteration 330, loss = 0.03153553\n",
      "Validation score: 0.504985\n",
      "Iteration 331, loss = 0.03136655\n",
      "Validation score: 0.506704\n",
      "Iteration 332, loss = 0.03119842\n",
      "Validation score: 0.508597\n",
      "Iteration 333, loss = 0.03102933\n",
      "Validation score: 0.510450\n",
      "Iteration 334, loss = 0.03086059\n",
      "Validation score: 0.512118\n",
      "Iteration 335, loss = 0.03069228\n",
      "Validation score: 0.514087\n",
      "Iteration 336, loss = 0.03052457\n",
      "Validation score: 0.515826\n",
      "Iteration 337, loss = 0.03035418\n",
      "Validation score: 0.517823\n",
      "Iteration 338, loss = 0.03018637\n",
      "Validation score: 0.519461\n",
      "Iteration 339, loss = 0.03001785\n",
      "Validation score: 0.521463\n",
      "Iteration 340, loss = 0.02984854\n",
      "Validation score: 0.523072\n",
      "Iteration 341, loss = 0.02968156\n",
      "Validation score: 0.525168\n",
      "Iteration 342, loss = 0.02951113\n",
      "Validation score: 0.526650\n",
      "Iteration 343, loss = 0.02934540\n",
      "Validation score: 0.528834\n",
      "Iteration 344, loss = 0.02917483\n",
      "Validation score: 0.530510\n",
      "Iteration 345, loss = 0.02900736\n",
      "Validation score: 0.532393\n",
      "Iteration 346, loss = 0.02883761\n",
      "Validation score: 0.534104\n",
      "Iteration 347, loss = 0.02867048\n",
      "Validation score: 0.535961\n",
      "Iteration 348, loss = 0.02850105\n",
      "Validation score: 0.537878\n",
      "Iteration 349, loss = 0.02833384\n",
      "Validation score: 0.539587\n",
      "Iteration 350, loss = 0.02816596\n",
      "Validation score: 0.541542\n",
      "Iteration 351, loss = 0.02799901\n",
      "Validation score: 0.543314\n",
      "Iteration 352, loss = 0.02783356\n",
      "Validation score: 0.545039\n",
      "Iteration 353, loss = 0.02766596\n",
      "Validation score: 0.546994\n",
      "Iteration 354, loss = 0.02749780\n",
      "Validation score: 0.548863\n",
      "Iteration 355, loss = 0.02733150\n",
      "Validation score: 0.550579\n",
      "Iteration 356, loss = 0.02716573\n",
      "Validation score: 0.552557\n",
      "Iteration 357, loss = 0.02699896\n",
      "Validation score: 0.554385\n",
      "Iteration 358, loss = 0.02683553\n",
      "Validation score: 0.556206\n",
      "Iteration 359, loss = 0.02666838\n",
      "Validation score: 0.558185\n",
      "Iteration 360, loss = 0.02650313\n",
      "Validation score: 0.559820\n",
      "Iteration 361, loss = 0.02633928\n",
      "Validation score: 0.561775\n",
      "Iteration 362, loss = 0.02617525\n",
      "Validation score: 0.563698\n",
      "Iteration 363, loss = 0.02601245\n",
      "Validation score: 0.565134\n",
      "Iteration 364, loss = 0.02584809\n",
      "Validation score: 0.567286\n",
      "Iteration 365, loss = 0.02568356\n",
      "Validation score: 0.568996\n",
      "Iteration 366, loss = 0.02552094\n",
      "Validation score: 0.570747\n",
      "Iteration 367, loss = 0.02535966\n",
      "Validation score: 0.572733\n",
      "Iteration 368, loss = 0.02519688\n",
      "Validation score: 0.574368\n",
      "Iteration 369, loss = 0.02503428\n",
      "Validation score: 0.575985\n",
      "Iteration 370, loss = 0.02487540\n",
      "Validation score: 0.578065\n",
      "Iteration 371, loss = 0.02471328\n",
      "Validation score: 0.579566\n",
      "Iteration 372, loss = 0.02455328\n",
      "Validation score: 0.581688\n",
      "Iteration 373, loss = 0.02439325\n",
      "Validation score: 0.583211\n",
      "Iteration 374, loss = 0.02423239\n",
      "Validation score: 0.585249\n",
      "Iteration 375, loss = 0.02407278\n",
      "Validation score: 0.586776\n",
      "Iteration 376, loss = 0.02391436\n",
      "Validation score: 0.588628\n",
      "Iteration 377, loss = 0.02375692\n",
      "Validation score: 0.590308\n",
      "Iteration 378, loss = 0.02359999\n",
      "Validation score: 0.592273\n",
      "Iteration 379, loss = 0.02344230\n",
      "Validation score: 0.594029\n",
      "Iteration 380, loss = 0.02328616\n",
      "Validation score: 0.595578\n",
      "Iteration 381, loss = 0.02313092\n",
      "Validation score: 0.597471\n",
      "Iteration 382, loss = 0.02297654\n",
      "Validation score: 0.599181\n",
      "Iteration 383, loss = 0.02282166\n",
      "Validation score: 0.601008\n",
      "Iteration 384, loss = 0.02266915\n",
      "Validation score: 0.602381\n",
      "Iteration 385, loss = 0.02251459\n",
      "Validation score: 0.604413\n",
      "Iteration 386, loss = 0.02236199\n",
      "Validation score: 0.605854\n",
      "Iteration 387, loss = 0.02220992\n",
      "Validation score: 0.607741\n",
      "Iteration 388, loss = 0.02205874\n",
      "Validation score: 0.609565\n",
      "Iteration 389, loss = 0.02190929\n",
      "Validation score: 0.610816\n",
      "Iteration 390, loss = 0.02175754\n",
      "Validation score: 0.612943\n",
      "Iteration 391, loss = 0.02160783\n",
      "Validation score: 0.614216\n",
      "Iteration 392, loss = 0.02146040\n",
      "Validation score: 0.616337\n",
      "Iteration 393, loss = 0.02131249\n",
      "Validation score: 0.617694\n",
      "Iteration 394, loss = 0.02116239\n",
      "Validation score: 0.619496\n",
      "Iteration 395, loss = 0.02101504\n",
      "Validation score: 0.621181\n",
      "Iteration 396, loss = 0.02086777\n",
      "Validation score: 0.622744\n",
      "Iteration 397, loss = 0.02072293\n",
      "Validation score: 0.624508\n",
      "Iteration 398, loss = 0.02057750\n",
      "Validation score: 0.625861\n",
      "Iteration 399, loss = 0.02043329\n",
      "Validation score: 0.627636\n",
      "Iteration 400, loss = 0.02028953\n",
      "Validation score: 0.629204\n",
      "Iteration 401, loss = 0.02014768\n",
      "Validation score: 0.630874\n",
      "Iteration 402, loss = 0.02000572\n",
      "Validation score: 0.632087\n",
      "Iteration 403, loss = 0.01986523\n",
      "Validation score: 0.634125\n",
      "Iteration 404, loss = 0.01972292\n",
      "Validation score: 0.635473\n",
      "Iteration 405, loss = 0.01958296\n",
      "Validation score: 0.637186\n",
      "Iteration 406, loss = 0.01944359\n",
      "Validation score: 0.638808\n",
      "Iteration 407, loss = 0.01930614\n",
      "Validation score: 0.640233\n",
      "Iteration 408, loss = 0.01916806\n",
      "Validation score: 0.641907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 409, loss = 0.01903113\n",
      "Validation score: 0.643429\n",
      "Iteration 410, loss = 0.01889490\n",
      "Validation score: 0.644803\n",
      "Iteration 411, loss = 0.01876095\n",
      "Validation score: 0.646439\n",
      "Iteration 412, loss = 0.01862894\n",
      "Validation score: 0.647943\n",
      "Iteration 413, loss = 0.01849529\n",
      "Validation score: 0.649232\n",
      "Iteration 414, loss = 0.01835977\n",
      "Validation score: 0.650897\n",
      "Iteration 415, loss = 0.01822757\n",
      "Validation score: 0.652341\n",
      "Iteration 416, loss = 0.01809632\n",
      "Validation score: 0.653897\n",
      "Iteration 417, loss = 0.01796482\n",
      "Validation score: 0.655248\n",
      "Iteration 418, loss = 0.01783534\n",
      "Validation score: 0.656868\n",
      "Iteration 419, loss = 0.01770650\n",
      "Validation score: 0.658097\n",
      "Iteration 420, loss = 0.01757814\n",
      "Validation score: 0.659700\n",
      "Iteration 421, loss = 0.01745052\n",
      "Validation score: 0.661221\n",
      "Iteration 422, loss = 0.01732420\n",
      "Validation score: 0.662620\n",
      "Iteration 423, loss = 0.01719874\n",
      "Validation score: 0.663911\n",
      "Iteration 424, loss = 0.01707360\n",
      "Validation score: 0.665447\n",
      "Iteration 425, loss = 0.01694988\n",
      "Validation score: 0.666681\n",
      "Iteration 426, loss = 0.01682618\n",
      "Validation score: 0.668327\n",
      "Iteration 427, loss = 0.01670343\n",
      "Validation score: 0.669554\n",
      "Iteration 428, loss = 0.01658122\n",
      "Validation score: 0.671038\n",
      "Iteration 429, loss = 0.01646022\n",
      "Validation score: 0.672060\n",
      "Iteration 430, loss = 0.01634018\n",
      "Validation score: 0.673706\n",
      "Iteration 431, loss = 0.01622249\n",
      "Validation score: 0.674740\n",
      "Iteration 432, loss = 0.01610401\n",
      "Validation score: 0.676342\n",
      "Iteration 433, loss = 0.01598579\n",
      "Validation score: 0.677426\n",
      "Iteration 434, loss = 0.01586864\n",
      "Validation score: 0.678958\n",
      "Iteration 435, loss = 0.01575258\n",
      "Validation score: 0.679890\n",
      "Iteration 436, loss = 0.01563864\n",
      "Validation score: 0.681704\n",
      "Iteration 437, loss = 0.01552551\n",
      "Validation score: 0.682525\n",
      "Iteration 438, loss = 0.01541142\n",
      "Validation score: 0.684310\n",
      "Iteration 439, loss = 0.01529891\n",
      "Validation score: 0.685288\n",
      "Iteration 440, loss = 0.01518503\n",
      "Validation score: 0.686697\n",
      "Iteration 441, loss = 0.01507396\n",
      "Validation score: 0.687800\n",
      "Iteration 442, loss = 0.01496539\n",
      "Validation score: 0.689100\n",
      "Iteration 443, loss = 0.01485539\n",
      "Validation score: 0.690300\n",
      "Iteration 444, loss = 0.01474759\n",
      "Validation score: 0.691280\n",
      "Iteration 445, loss = 0.01464124\n",
      "Validation score: 0.692730\n",
      "Iteration 446, loss = 0.01453649\n",
      "Validation score: 0.693414\n",
      "Iteration 447, loss = 0.01442864\n",
      "Validation score: 0.695007\n",
      "Iteration 448, loss = 0.01432338\n",
      "Validation score: 0.695947\n",
      "Iteration 449, loss = 0.01421880\n",
      "Validation score: 0.697065\n",
      "Iteration 450, loss = 0.01411568\n",
      "Validation score: 0.698157\n",
      "Iteration 451, loss = 0.01401414\n",
      "Validation score: 0.699286\n",
      "Iteration 452, loss = 0.01391312\n",
      "Validation score: 0.700467\n",
      "Iteration 453, loss = 0.01381321\n",
      "Validation score: 0.701416\n",
      "Iteration 454, loss = 0.01371324\n",
      "Validation score: 0.702477\n",
      "Iteration 455, loss = 0.01361460\n",
      "Validation score: 0.703552\n",
      "Iteration 456, loss = 0.01351632\n",
      "Validation score: 0.704549\n",
      "Iteration 457, loss = 0.01341912\n",
      "Validation score: 0.705604\n",
      "Iteration 458, loss = 0.01332391\n",
      "Validation score: 0.706693\n",
      "Iteration 459, loss = 0.01322846\n",
      "Validation score: 0.707737\n",
      "Iteration 460, loss = 0.01313407\n",
      "Validation score: 0.708545\n",
      "Iteration 461, loss = 0.01304113\n",
      "Validation score: 0.709790\n",
      "Iteration 462, loss = 0.01294828\n",
      "Validation score: 0.710618\n",
      "Iteration 463, loss = 0.01285669\n",
      "Validation score: 0.711803\n",
      "Iteration 464, loss = 0.01276708\n",
      "Validation score: 0.712320\n",
      "Iteration 465, loss = 0.01267809\n",
      "Validation score: 0.713675\n",
      "Iteration 466, loss = 0.01258593\n",
      "Validation score: 0.714574\n",
      "Iteration 467, loss = 0.01249696\n",
      "Validation score: 0.715493\n",
      "Iteration 468, loss = 0.01240957\n",
      "Validation score: 0.716459\n",
      "Iteration 469, loss = 0.01232473\n",
      "Validation score: 0.717139\n",
      "Iteration 470, loss = 0.01223830\n",
      "Validation score: 0.718297\n",
      "Iteration 471, loss = 0.01215250\n",
      "Validation score: 0.719177\n",
      "Iteration 472, loss = 0.01206825\n",
      "Validation score: 0.719836\n",
      "Iteration 473, loss = 0.01198642\n",
      "Validation score: 0.720959\n",
      "Iteration 474, loss = 0.01190225\n",
      "Validation score: 0.721724\n",
      "Iteration 475, loss = 0.01182044\n",
      "Validation score: 0.722811\n",
      "Iteration 476, loss = 0.01174131\n",
      "Validation score: 0.723621\n",
      "Iteration 477, loss = 0.01165964\n",
      "Validation score: 0.724426\n",
      "Iteration 478, loss = 0.01158132\n",
      "Validation score: 0.725247\n",
      "Iteration 479, loss = 0.01150310\n",
      "Validation score: 0.726107\n",
      "Iteration 480, loss = 0.01142615\n",
      "Validation score: 0.726710\n",
      "Iteration 481, loss = 0.01134971\n",
      "Validation score: 0.727872\n",
      "Iteration 482, loss = 0.01127385\n",
      "Validation score: 0.728403\n",
      "Iteration 483, loss = 0.01119812\n",
      "Validation score: 0.729490\n",
      "Iteration 484, loss = 0.01112486\n",
      "Validation score: 0.729988\n",
      "Iteration 485, loss = 0.01105227\n",
      "Validation score: 0.730907\n",
      "Iteration 486, loss = 0.01098065\n",
      "Validation score: 0.731873\n",
      "Iteration 487, loss = 0.01090964\n",
      "Validation score: 0.732166\n",
      "Iteration 488, loss = 0.01083867\n",
      "Validation score: 0.733445\n",
      "Iteration 489, loss = 0.01076654\n",
      "Validation score: 0.733663\n",
      "Iteration 490, loss = 0.01069910\n",
      "Validation score: 0.734849\n",
      "Iteration 491, loss = 0.01062715\n",
      "Validation score: 0.735391\n",
      "Iteration 492, loss = 0.01055969\n",
      "Validation score: 0.736347\n",
      "Iteration 493, loss = 0.01049368\n",
      "Validation score: 0.736816\n",
      "Iteration 494, loss = 0.01042651\n",
      "Validation score: 0.737709\n",
      "Iteration 495, loss = 0.01036138\n",
      "Validation score: 0.738225\n",
      "Iteration 496, loss = 0.01029602\n",
      "Validation score: 0.739133\n",
      "Iteration 497, loss = 0.01023312\n",
      "Validation score: 0.739501\n",
      "Iteration 498, loss = 0.01016992\n",
      "Validation score: 0.740498\n",
      "Iteration 499, loss = 0.01010628\n",
      "Validation score: 0.740937\n",
      "Iteration 500, loss = 0.01004487\n",
      "Validation score: 0.741798\n",
      "Iteration 501, loss = 0.00998419\n",
      "Validation score: 0.742225\n",
      "Iteration 502, loss = 0.00992578\n",
      "Validation score: 0.743020\n",
      "Iteration 503, loss = 0.00986456\n",
      "Validation score: 0.743723\n",
      "Iteration 504, loss = 0.00980700\n",
      "Validation score: 0.744059\n",
      "Iteration 505, loss = 0.00975032\n",
      "Validation score: 0.745022\n",
      "Iteration 506, loss = 0.00969003\n",
      "Validation score: 0.745280\n",
      "Iteration 507, loss = 0.00963474\n",
      "Validation score: 0.746215\n",
      "Iteration 508, loss = 0.00957805\n",
      "Validation score: 0.746735\n",
      "Iteration 509, loss = 0.00952216\n",
      "Validation score: 0.747267\n",
      "Iteration 510, loss = 0.00946825\n",
      "Validation score: 0.747955\n",
      "Iteration 511, loss = 0.00941435\n",
      "Validation score: 0.748526\n",
      "Iteration 512, loss = 0.00936065\n",
      "Validation score: 0.749084\n",
      "Iteration 513, loss = 0.00930884\n",
      "Validation score: 0.749623\n",
      "Iteration 514, loss = 0.00925645\n",
      "Validation score: 0.750125\n",
      "Iteration 515, loss = 0.00920743\n",
      "Validation score: 0.750810\n",
      "Iteration 516, loss = 0.00915553\n",
      "Validation score: 0.751182\n",
      "Iteration 517, loss = 0.00910633\n",
      "Validation score: 0.751871\n",
      "Iteration 518, loss = 0.00905745\n",
      "Validation score: 0.752303\n",
      "Iteration 519, loss = 0.00900950\n",
      "Validation score: 0.752912\n",
      "Iteration 520, loss = 0.00896064\n",
      "Validation score: 0.753362\n",
      "Iteration 521, loss = 0.00891359\n",
      "Validation score: 0.753897\n",
      "Iteration 522, loss = 0.00886726\n",
      "Validation score: 0.754343\n",
      "Iteration 523, loss = 0.00882229\n",
      "Validation score: 0.754877\n",
      "Iteration 524, loss = 0.00877639\n",
      "Validation score: 0.755407\n",
      "Iteration 525, loss = 0.00873149\n",
      "Validation score: 0.755850\n",
      "Iteration 526, loss = 0.00868836\n",
      "Validation score: 0.756362\n",
      "Iteration 527, loss = 0.00864416\n",
      "Validation score: 0.756780\n",
      "Iteration 528, loss = 0.00860120\n",
      "Validation score: 0.757332\n",
      "Iteration 529, loss = 0.00855894\n",
      "Validation score: 0.757695\n",
      "Iteration 530, loss = 0.00851762\n",
      "Validation score: 0.758215\n",
      "Iteration 531, loss = 0.00847680\n",
      "Validation score: 0.758604\n",
      "Iteration 532, loss = 0.00843739\n",
      "Validation score: 0.759125\n",
      "Iteration 533, loss = 0.00839693\n",
      "Validation score: 0.759519\n",
      "Iteration 534, loss = 0.00835714\n",
      "Validation score: 0.759929\n",
      "Iteration 535, loss = 0.00831882\n",
      "Validation score: 0.760403\n",
      "Iteration 536, loss = 0.00828017\n",
      "Validation score: 0.760701\n",
      "Iteration 537, loss = 0.00824365\n",
      "Validation score: 0.761237\n",
      "Iteration 538, loss = 0.00820684\n",
      "Validation score: 0.761530\n",
      "Iteration 539, loss = 0.00817106\n",
      "Validation score: 0.762016\n",
      "Iteration 540, loss = 0.00813564\n",
      "Validation score: 0.762292\n",
      "Iteration 541, loss = 0.00809924\n",
      "Validation score: 0.762773\n",
      "Iteration 542, loss = 0.00806658\n",
      "Validation score: 0.763038\n",
      "Iteration 543, loss = 0.00803005\n",
      "Validation score: 0.763598\n",
      "Iteration 544, loss = 0.00799622\n",
      "Validation score: 0.763896\n",
      "Iteration 545, loss = 0.00796322\n",
      "Validation score: 0.764231\n",
      "Iteration 546, loss = 0.00793038\n",
      "Validation score: 0.764695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 547, loss = 0.00789797\n",
      "Validation score: 0.764840\n",
      "Iteration 548, loss = 0.00786633\n",
      "Validation score: 0.765407\n",
      "Iteration 549, loss = 0.00783375\n",
      "Validation score: 0.765536\n",
      "Iteration 550, loss = 0.00780445\n",
      "Validation score: 0.766093\n",
      "Iteration 551, loss = 0.00777282\n",
      "Validation score: 0.766331\n",
      "Iteration 552, loss = 0.00774282\n",
      "Validation score: 0.766712\n",
      "Iteration 553, loss = 0.00771354\n",
      "Validation score: 0.766997\n",
      "Iteration 554, loss = 0.00768435\n",
      "Validation score: 0.767389\n",
      "Iteration 555, loss = 0.00765653\n",
      "Validation score: 0.767593\n",
      "Iteration 556, loss = 0.00762940\n",
      "Validation score: 0.768021\n",
      "Iteration 557, loss = 0.00760035\n",
      "Validation score: 0.768192\n",
      "Iteration 558, loss = 0.00757325\n",
      "Validation score: 0.768647\n",
      "Iteration 559, loss = 0.00754697\n",
      "Validation score: 0.768798\n",
      "Iteration 560, loss = 0.00752021\n",
      "Validation score: 0.769223\n",
      "Iteration 561, loss = 0.00749572\n",
      "Validation score: 0.769325\n",
      "Iteration 562, loss = 0.00746953\n",
      "Validation score: 0.769807\n",
      "Iteration 563, loss = 0.00744404\n",
      "Validation score: 0.769981\n",
      "Iteration 564, loss = 0.00741985\n",
      "Validation score: 0.770334\n",
      "Iteration 565, loss = 0.00739471\n",
      "Validation score: 0.770543\n",
      "Iteration 566, loss = 0.00737182\n",
      "Validation score: 0.770881\n",
      "Iteration 567, loss = 0.00734860\n",
      "Validation score: 0.771036\n",
      "Iteration 568, loss = 0.00732505\n",
      "Validation score: 0.771414\n",
      "Iteration 569, loss = 0.00730206\n",
      "Validation score: 0.771616\n",
      "Iteration 570, loss = 0.00727939\n",
      "Validation score: 0.771944\n",
      "Iteration 571, loss = 0.00725809\n",
      "Validation score: 0.772107\n",
      "Iteration 572, loss = 0.00723564\n",
      "Validation score: 0.772430\n",
      "Iteration 573, loss = 0.00721475\n",
      "Validation score: 0.772578\n",
      "Iteration 574, loss = 0.00719363\n",
      "Validation score: 0.772907\n",
      "Iteration 575, loss = 0.00717355\n",
      "Validation score: 0.773046\n",
      "Iteration 576, loss = 0.00715379\n",
      "Validation score: 0.773388\n",
      "Iteration 577, loss = 0.00713321\n",
      "Validation score: 0.773467\n",
      "Iteration 578, loss = 0.00711402\n",
      "Validation score: 0.773834\n",
      "Iteration 579, loss = 0.00709446\n",
      "Validation score: 0.773811\n",
      "Iteration 580, loss = 0.00707862\n",
      "Validation score: 0.774285\n",
      "Iteration 581, loss = 0.00706038\n",
      "Validation score: 0.774288\n",
      "Iteration 582, loss = 0.00704245\n",
      "Validation score: 0.774636\n",
      "Iteration 583, loss = 0.00702222\n",
      "Validation score: 0.774899\n",
      "Iteration 584, loss = 0.00700865\n",
      "Validation score: 0.774985\n",
      "Iteration 585, loss = 0.00700387\n",
      "Validation score: 0.775247\n",
      "Iteration 586, loss = 0.00702381\n",
      "Validation score: 0.775501\n",
      "Iteration 587, loss = 0.00698937\n",
      "Validation score: 0.775508\n",
      "Iteration 588, loss = 0.00694514\n",
      "Validation score: 0.775882\n",
      "Iteration 589, loss = 0.00696126\n",
      "Validation score: 0.775949\n",
      "Iteration 590, loss = 0.00690441\n",
      "Validation score: 0.776239\n",
      "Iteration 591, loss = 0.00713942\n",
      "Validation score: 0.776383\n",
      "Iteration 592, loss = 0.00801750\n",
      "Validation score: 0.776619\n",
      "Iteration 593, loss = 0.00774996\n",
      "Validation score: 0.776780\n",
      "Iteration 594, loss = 0.00685854\n",
      "Validation score: 0.776892\n",
      "Iteration 595, loss = 0.00713199\n",
      "Validation score: 0.777146\n",
      "Iteration 596, loss = 0.00697860\n",
      "Validation score: 0.777204\n",
      "Iteration 597, loss = 0.00687193\n",
      "Validation score: 0.777413\n",
      "Iteration 598, loss = 0.00694166\n",
      "Validation score: 0.777638\n",
      "Iteration 599, loss = 0.00691461\n",
      "Validation score: 0.777758\n",
      "Iteration 600, loss = 0.00714647\n",
      "Validation score: 0.777876\n",
      "Iteration 601, loss = 0.00674801\n",
      "Validation score: 0.778105\n",
      "Iteration 602, loss = 0.00931557\n",
      "Validation score: 0.778167\n",
      "Iteration 603, loss = 0.00812832\n",
      "Validation score: 0.778411\n",
      "Iteration 604, loss = 0.00721305\n",
      "Validation score: 0.778545\n",
      "Iteration 605, loss = 0.00999136\n",
      "Validation score: 0.778679\n",
      "Iteration 606, loss = 0.01191762\n",
      "Validation score: 0.778872\n",
      "Iteration 607, loss = 0.02316690\n",
      "Validation score: 0.778971\n",
      "Iteration 608, loss = 0.01403767\n",
      "Validation score: 0.779027\n",
      "Iteration 609, loss = 0.01080471\n",
      "Validation score: 0.779260\n",
      "Iteration 610, loss = 0.04123499\n",
      "Validation score: 0.779426\n",
      "Iteration 611, loss = 0.11909402\n",
      "Validation score: 0.779424\n",
      "Iteration 612, loss = 0.00679244\n",
      "Validation score: 0.779713\n",
      "Iteration 613, loss = 0.65778588\n",
      "Validation score: 0.779767\n",
      "Iteration 614, loss = 5.88661520\n",
      "Validation score: 0.779828\n",
      "Iteration 615, loss = 30.80409655\n",
      "Validation score: 0.780099\n",
      "Iteration 616, loss = 1.78962783\n",
      "Validation score: 0.780025\n",
      "Iteration 617, loss = 29.59570538\n",
      "Validation score: 0.780347\n",
      "Iteration 618, loss = 355.76864312\n",
      "Validation score: 0.780249\n",
      "Iteration 619, loss = 281.06588684\n",
      "Validation score: 0.780569\n",
      "Iteration 620, loss = 1147.11192258\n",
      "Validation score: 0.780432\n",
      "Iteration 621, loss = 2410.32782773\n",
      "Validation score: 0.780793\n",
      "Iteration 622, loss = 1290.93037950\n",
      "Validation score: 0.780663\n",
      "Iteration 623, loss = 3496.99248983\n",
      "Validation score: 0.781050\n",
      "Iteration 624, loss = 9696.52043140\n",
      "Validation score: 0.781133\n",
      "Iteration 625, loss = 9146.77302239\n",
      "Validation score: 0.781203\n",
      "Iteration 626, loss = 75993.71955126\n",
      "Validation score: 0.781364\n",
      "Iteration 627, loss = 374.57945247\n",
      "Validation score: 0.781468\n",
      "Iteration 628, loss = 292619.60149461\n",
      "Validation score: 0.781587\n",
      "Iteration 629, loss = 2626407.63324618\n",
      "Validation score: 0.781616\n",
      "Iteration 630, loss = 12577536.33556645\n",
      "Validation score: 0.781802\n",
      "Iteration 631, loss = 74177428.58446534\n",
      "Validation score: 0.781867\n",
      "Iteration 632, loss = 9041.76123794\n",
      "Validation score: 0.781910\n",
      "Iteration 633, loss = 2824370656.47149277\n",
      "Validation score: 0.782058\n",
      "Iteration 634, loss = 2871304595.84779119\n",
      "Validation score: 0.782133\n",
      "Iteration 635, loss = 4892125523.82263756\n",
      "Validation score: 0.782254\n",
      "Iteration 636, loss = 72582009143.36370850\n",
      "Validation score: 0.782401\n",
      "Iteration 637, loss = 9215877100.85362434\n",
      "Validation score: 0.782375\n",
      "Iteration 638, loss = 268504145640.37030029\n",
      "Validation score: 0.782512\n",
      "Iteration 639, loss = 2495872772281.61230469\n",
      "Validation score: 0.782746\n",
      "Iteration 640, loss = 1850884371319.31958008\n",
      "Validation score: 0.782576\n",
      "Iteration 641, loss = 123694463456.90734863\n",
      "Validation score: 0.782850\n",
      "Iteration 642, loss = 117229778761.03527832\n",
      "Validation score: 0.782927\n",
      "Iteration 643, loss = 60485565875.17491150\n",
      "Validation score: 0.782907\n",
      "Iteration 644, loss = 34890922709.43955994\n",
      "Validation score: 0.783108\n",
      "Iteration 645, loss = 146495709106.88131714\n",
      "Validation score: 0.783194\n",
      "Iteration 646, loss = 887728259271.59484863\n",
      "Validation score: 0.783131\n",
      "Iteration 647, loss = 2737189835304.90087891\n",
      "Validation score: 0.783470\n",
      "Iteration 648, loss = 5076426510607.86035156\n",
      "Validation score: 0.783278\n",
      "Iteration 649, loss = 17929247206264.51953125\n",
      "Validation score: 0.783798\n",
      "Iteration 650, loss = 134269061308151.23437500\n",
      "Validation score: 0.783347\n",
      "Iteration 651, loss = 541282803868606.68750000\n",
      "Validation score: 0.783752\n",
      "Iteration 652, loss = 2689000612339.21826172\n",
      "Validation score: 0.786937\n",
      "Iteration 653, loss = 3152348423823263.00000000\n",
      "Validation score: 0.780421\n",
      "Iteration 654, loss = 3813268644528834.00000000\n",
      "Validation score: 0.784917\n",
      "Iteration 655, loss = 41788235703301.65625000\n",
      "Validation score: 0.789336\n",
      "Iteration 656, loss = 4291756112370853.00000000\n",
      "Validation score: 0.780805\n",
      "Iteration 657, loss = 1606725639459115.75000000\n",
      "Validation score: 0.782502\n",
      "Iteration 658, loss = 346337311844479.31250000\n",
      "Validation score: 0.785555\n",
      "Iteration 659, loss = 77672331069025.84375000\n",
      "Validation score: 0.785404\n",
      "Iteration 660, loss = 538723317950209.56250000\n",
      "Validation score: 0.782604\n",
      "Iteration 661, loss = 918363596027149.87500000\n",
      "Validation score: 0.784121\n",
      "Iteration 662, loss = 91816575430159.73437500\n",
      "Validation score: 0.791113\n",
      "Iteration 663, loss = 5890749548609875.00000000\n",
      "Validation score: 0.787110\n",
      "Iteration 664, loss = 22595666375607.53125000\n",
      "Validation score: 0.774261\n",
      "Iteration 665, loss = 11953942356011192.00000000\n",
      "Validation score: 0.788565\n",
      "Iteration 666, loss = 9260888068581610.00000000\n",
      "Validation score: 0.789290\n",
      "Iteration 667, loss = 60903309985833.75000000\n",
      "Validation score: 0.781382\n",
      "Iteration 668, loss = 1385060452453250.50000000\n",
      "Validation score: 0.786148\n",
      "Iteration 669, loss = 477380237132271.68750000\n",
      "Validation score: 0.786583\n",
      "Iteration 670, loss = 4305281906140.82861328\n",
      "Validation score: 0.784578\n",
      "Iteration 671, loss = 434913583707326.50000000\n",
      "Validation score: 0.784727\n",
      "Iteration 672, loss = 328936264519729.87500000\n",
      "Validation score: 0.787895\n",
      "Iteration 673, loss = 280579079873287.28125000\n",
      "Validation score: 0.785095\n",
      "Iteration 674, loss = 322544049456911.75000000\n",
      "Validation score: 0.785560\n",
      "Iteration 675, loss = 14813539883668.71289062\n",
      "Validation score: 0.786595\n",
      "Iteration 676, loss = 14340962753044.70312500\n",
      "Validation score: 0.786111\n",
      "Iteration 677, loss = 23487819239530.73046875\n",
      "Validation score: 0.786090\n",
      "Iteration 678, loss = 316917340128.47705078\n",
      "Validation score: 0.786639\n",
      "Iteration 679, loss = 4055708989344.97802734\n",
      "Validation score: 0.786451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 680, loss = 81107591848.93783569\n",
      "Validation score: 0.786350\n",
      "Iteration 681, loss = 1256785429706.32568359\n",
      "Validation score: 0.786570\n",
      "Iteration 682, loss = 1401155565499.10937500\n",
      "Validation score: 0.786741\n",
      "Iteration 683, loss = 77800274131.16108704\n",
      "Validation score: 0.786587\n",
      "Iteration 684, loss = 250671022075.68399048\n",
      "Validation score: 0.786751\n",
      "Iteration 685, loss = 514006151333.52618408\n",
      "Validation score: 0.786908\n",
      "Iteration 686, loss = 48717147643.85791016\n",
      "Validation score: 0.786717\n",
      "Iteration 687, loss = 934925377195.63464355\n",
      "Validation score: 0.786879\n",
      "Iteration 688, loss = 815627141893.40258789\n",
      "Validation score: 0.787126\n",
      "Iteration 689, loss = 591576207692.99536133\n",
      "Validation score: 0.786977\n",
      "Iteration 690, loss = 1516330723421.30151367\n",
      "Validation score: 0.787175\n",
      "Iteration 691, loss = 90017138858.65182495\n",
      "Validation score: 0.787167\n",
      "Iteration 692, loss = 488429735584.12133789\n",
      "Validation score: 0.787203\n",
      "Iteration 693, loss = 734235764528.21166992\n",
      "Validation score: 0.787333\n",
      "Iteration 694, loss = 677112897763.55322266\n",
      "Validation score: 0.787403\n",
      "Iteration 695, loss = 437266606412.88049316\n",
      "Validation score: 0.787374\n",
      "Iteration 696, loss = 295052618966.73437500\n",
      "Validation score: 0.787468\n",
      "Iteration 697, loss = 23325863581.14101028\n",
      "Validation score: 0.787670\n",
      "Iteration 698, loss = 1166792493525.01879883\n",
      "Validation score: 0.787521\n",
      "Iteration 699, loss = 697981153328.40490723\n",
      "Validation score: 0.787566\n",
      "Iteration 700, loss = 75916586988.64010620\n",
      "Validation score: 0.787746\n",
      "Iteration 701, loss = 15399077164.25520134\n",
      "Validation score: 0.787776\n",
      "Iteration 702, loss = 68292491.83937116\n",
      "Validation score: 0.787761\n",
      "Iteration 703, loss = 109547580300.55714417\n",
      "Validation score: 0.787877\n",
      "Iteration 704, loss = 18367703997.81502914\n",
      "Validation score: 0.787970\n",
      "Iteration 705, loss = 77682818973.44259644\n",
      "Validation score: 0.787902\n",
      "Iteration 706, loss = 84350248558.46864319\n",
      "Validation score: 0.788028\n",
      "Iteration 707, loss = 8313533997.09366798\n",
      "Validation score: 0.788145\n",
      "Iteration 708, loss = 294187130019.96020508\n",
      "Validation score: 0.787945\n",
      "Iteration 709, loss = 4830670546.36166668\n",
      "Validation score: 0.788122\n",
      "Iteration 710, loss = 470746342561.93011475\n",
      "Validation score: 0.788238\n",
      "Iteration 711, loss = 635130673288.48962402\n",
      "Validation score: 0.788213\n",
      "Iteration 712, loss = 573794174035.16467285\n",
      "Validation score: 0.788326\n",
      "Iteration 713, loss = 816475485643.76306152\n",
      "Validation score: 0.788478\n",
      "Iteration 714, loss = 131804270322.74496460\n",
      "Validation score: 0.788255\n",
      "Iteration 715, loss = 2608309634866.06884766\n",
      "Validation score: 0.788482\n",
      "Iteration 716, loss = 35067008518.93199158\n",
      "Validation score: 0.788732\n",
      "Iteration 717, loss = 6769512856561.53906250\n",
      "Validation score: 0.788657\n",
      "Iteration 718, loss = 211947206800.33969116\n",
      "Validation score: 0.788099\n",
      "Iteration 719, loss = 23921691891122.42578125\n",
      "Validation score: 0.789111\n",
      "Iteration 720, loss = 20827598234221.07421875\n",
      "Validation score: 0.788588\n",
      "Iteration 721, loss = 3882213769668.10058594\n",
      "Validation score: 0.788670\n",
      "Iteration 722, loss = 176822350459.13293457\n",
      "Validation score: 0.788848\n",
      "Iteration 723, loss = 93877465792.71879578\n",
      "Validation score: 0.789003\n",
      "Iteration 724, loss = 1609310832277.24584961\n",
      "Validation score: 0.788754\n",
      "Iteration 725, loss = 3038804831561.99755859\n",
      "Validation score: 0.788896\n",
      "Iteration 726, loss = 812468746720.60339355\n",
      "Validation score: 0.789149\n",
      "Iteration 727, loss = 3186193607142.92382812\n",
      "Validation score: 0.788926\n",
      "Iteration 728, loss = 2758306352347.02636719\n",
      "Validation score: 0.789220\n",
      "Iteration 729, loss = 1235934876581.30883789\n",
      "Validation score: 0.789168\n",
      "Iteration 730, loss = 2631771420.82394791\n",
      "Validation score: 0.789029\n",
      "Iteration 731, loss = 3933629894238.62646484\n",
      "Validation score: 0.789277\n",
      "Iteration 732, loss = 1312860287251.34155273\n",
      "Validation score: 0.789486\n",
      "Iteration 733, loss = 1414675260259.37084961\n",
      "Validation score: 0.789271\n",
      "Iteration 734, loss = 1718364423232.46606445\n",
      "Validation score: 0.789424\n",
      "Iteration 735, loss = 47628696335.11983490\n",
      "Validation score: 0.789644\n",
      "Iteration 736, loss = 3979531217790.02734375\n",
      "Validation score: 0.789518\n",
      "Iteration 737, loss = 379141969595.36407471\n",
      "Validation score: 0.788842\n",
      "Iteration 738, loss = 45151006926715.31250000\n",
      "Validation score: 0.790207\n",
      "Iteration 739, loss = 116633605616118.59375000\n",
      "Validation score: 0.789857\n",
      "Iteration 740, loss = 4087559543587.05566406\n",
      "Validation score: 0.788407\n",
      "Iteration 741, loss = 310741155912556.56250000\n",
      "Validation score: 0.789213\n",
      "Iteration 742, loss = 632959975007347.50000000\n",
      "Validation score: 0.791031\n",
      "Iteration 743, loss = 1971738210170.01513672\n",
      "Validation score: 0.789350\n",
      "Iteration 744, loss = 52688996286294.53125000\n",
      "Validation score: 0.790160\n",
      "Iteration 745, loss = 15646018188111.14843750\n",
      "Validation score: 0.790127\n",
      "Iteration 746, loss = 995164741894.51672363\n",
      "Validation score: 0.790011\n",
      "Iteration 747, loss = 141998960880.55096436\n",
      "Validation score: 0.789809\n",
      "Iteration 748, loss = 9086930472533.56640625\n",
      "Validation score: 0.789905\n",
      "Iteration 749, loss = 20208193315952.39453125\n",
      "Validation score: 0.790420\n",
      "Iteration 750, loss = 3361798608155.01562500\n",
      "Validation score: 0.789429\n",
      "Iteration 751, loss = 49961843536949.28125000\n",
      "Validation score: 0.790755\n",
      "Iteration 752, loss = 75091233922621.21875000\n",
      "Validation score: 0.790044\n",
      "Iteration 753, loss = 128405464768613.62500000\n",
      "Validation score: 0.789875\n",
      "Iteration 754, loss = 82936335548151.01562500\n",
      "Validation score: 0.791485\n",
      "Iteration 755, loss = 141580329408376.00000000\n",
      "Validation score: 0.789900\n",
      "Iteration 756, loss = 303693688919353.68750000\n",
      "Validation score: 0.790418\n",
      "Iteration 757, loss = 141124664626133.62500000\n",
      "Validation score: 0.790894\n",
      "Iteration 758, loss = 9676297586422.88476562\n",
      "Validation score: 0.790227\n",
      "Iteration 759, loss = 9294575425403.67382812\n",
      "Validation score: 0.790590\n",
      "Iteration 760, loss = 23945843965420.69140625\n",
      "Validation score: 0.790827\n",
      "Iteration 761, loss = 423831579.42889220\n",
      "Validation score: 0.790141\n",
      "Iteration 762, loss = 73746345111841.12500000\n",
      "Validation score: 0.790459\n",
      "Iteration 763, loss = 306932518262499.81250000\n",
      "Validation score: 0.791482\n",
      "Iteration 764, loss = 113868527548822.54687500\n",
      "Validation score: 0.790231\n",
      "Iteration 765, loss = 5737076570609.96191406\n",
      "Validation score: 0.791144\n",
      "Iteration 766, loss = 8235924680005.23925781\n",
      "Validation score: 0.790676\n",
      "Iteration 767, loss = 26007914968230.71875000\n",
      "Validation score: 0.791017\n",
      "Iteration 768, loss = 541234797082.14941406\n",
      "Validation score: 0.791694\n",
      "Iteration 769, loss = 75190946526448.85937500\n",
      "Validation score: 0.791293\n",
      "Iteration 770, loss = 15770954178830.10742188\n",
      "Validation score: 0.789323\n",
      "Iteration 771, loss = 414203682781040.62500000\n",
      "Validation score: 0.792701\n",
      "Iteration 772, loss = 1398328396836290.25000000\n",
      "Validation score: 0.791744\n",
      "Iteration 773, loss = 28821245770738.78515625\n",
      "Validation score: 0.783151\n",
      "Iteration 774, loss = 6791010584100397.00000000\n",
      "Validation score: 0.798713\n",
      "Iteration 775, loss = 28234437894007872.00000000\n",
      "Validation score: 0.798943\n",
      "Iteration 776, loss = 3835416689705179.50000000\n",
      "Validation score: 0.730299\n",
      "Iteration 777, loss = 524561967211355264.00000000\n",
      "Validation score: 0.762162\n",
      "Iteration 778, loss = 13113653603534082.00000000\n",
      "Validation score: 0.816401\n",
      "Iteration 779, loss = 409777511483237632.00000000\n",
      "Validation score: 0.808887\n",
      "Iteration 780, loss = 174621318822707808.00000000\n",
      "Validation score: 0.783660\n",
      "Iteration 781, loss = 19486224118756156.00000000\n",
      "Validation score: 0.765631\n",
      "Iteration 782, loss = 159115532483504000.00000000\n",
      "Validation score: 0.787796\n",
      "Iteration 783, loss = 4736202725322251.00000000\n",
      "Validation score: 0.799231\n",
      "Iteration 784, loss = 118863963992247808.00000000\n",
      "Validation score: 0.793620\n",
      "Iteration 785, loss = 17309944640375958.00000000\n",
      "Validation score: 0.771034\n",
      "Iteration 786, loss = 144262262432051808.00000000\n",
      "Validation score: 0.784097\n",
      "Iteration 787, loss = 38986095793039512.00000000\n",
      "Validation score: 0.809999\n",
      "Iteration 788, loss = 282224320850535552.00000000\n",
      "Validation score: 0.790447\n",
      "Iteration 789, loss = 5442293386119353.00000000\n",
      "Validation score: 0.777560\n",
      "Iteration 790, loss = 20083625353907092.00000000\n",
      "Validation score: 0.799055\n",
      "Iteration 791, loss = 8394015435927238.00000000\n",
      "Validation score: 0.803805\n",
      "Iteration 792, loss = 305150382953141.87500000\n",
      "Validation score: 0.780856\n",
      "Iteration 793, loss = 14568379964676054.00000000\n",
      "Validation score: 0.782958\n",
      "Iteration 794, loss = 404500204080861.81250000\n",
      "Validation score: 0.798680\n",
      "Iteration 795, loss = 4662300957141119.00000000\n",
      "Validation score: 0.802005\n",
      "Iteration 796, loss = 2283678178850921.50000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.784102\n",
      "Iteration 797, loss = 6120114697515327.00000000\n",
      "Validation score: 0.788460\n",
      "Iteration 798, loss = 765077739542729.75000000\n",
      "Validation score: 0.800668\n",
      "Iteration 799, loss = 2601798729152699.00000000\n",
      "Validation score: 0.798659\n",
      "Iteration 800, loss = 466218153224933.37500000\n",
      "Validation score: 0.790623\n",
      "Iteration 801, loss = 1407475523120047.25000000\n",
      "Validation score: 0.791158\n",
      "Iteration 802, loss = 96467668344058.39062500\n",
      "Validation score: 0.796260\n",
      "Iteration 803, loss = 81540291668489.28125000\n",
      "Validation score: 0.797185\n",
      "Iteration 804, loss = 448980089736060.12500000\n",
      "Validation score: 0.796604\n",
      "Iteration 805, loss = 46600737077368.41406250\n",
      "Validation score: 0.791121\n",
      "Iteration 806, loss = 1238882777001648.50000000\n",
      "Validation score: 0.792883\n",
      "Iteration 807, loss = 52231699974135.24218750\n",
      "Validation score: 0.796382\n",
      "Iteration 808, loss = 397096881916660.37500000\n",
      "Validation score: 0.796515\n",
      "Iteration 809, loss = 52350786323059.83593750\n",
      "Validation score: 0.794103\n",
      "Iteration 810, loss = 119185861354170.14062500\n",
      "Validation score: 0.794036\n",
      "Iteration 811, loss = 26130490058980.47656250\n",
      "Validation score: 0.794890\n",
      "Iteration 812, loss = 14011574562470.66015625\n",
      "Validation score: 0.795553\n",
      "Iteration 813, loss = 12289402228217.43359375\n",
      "Validation score: 0.795216\n",
      "Iteration 814, loss = 509814645890.03808594\n",
      "Validation score: 0.794644\n",
      "Iteration 815, loss = 34364201886298.00781250\n",
      "Validation score: 0.794713\n",
      "Iteration 816, loss = 1801458394100.50195312\n",
      "Validation score: 0.795732\n",
      "Iteration 817, loss = 16217219782978.99218750\n",
      "Validation score: 0.795526\n",
      "Iteration 818, loss = 1823148183211.81347656\n",
      "Validation score: 0.795273\n",
      "Iteration 819, loss = 2485046293052.67138672\n",
      "Validation score: 0.795132\n",
      "Iteration 820, loss = 1133859791175.75781250\n",
      "Validation score: 0.795470\n",
      "Iteration 821, loss = 1068009056708.56994629\n",
      "Validation score: 0.795425\n",
      "Iteration 822, loss = 497083216093.85046387\n",
      "Validation score: 0.795420\n",
      "Iteration 823, loss = 11873361243.45659637\n",
      "Validation score: 0.795350\n",
      "Iteration 824, loss = 473837481624.96252441\n",
      "Validation score: 0.795499\n",
      "Iteration 825, loss = 62783826732.07320404\n",
      "Validation score: 0.795515\n",
      "Iteration 826, loss = 6628008106.29993153\n",
      "Validation score: 0.795527\n",
      "Iteration 827, loss = 60231050938.44241333\n",
      "Validation score: 0.795515\n",
      "Iteration 828, loss = 1732286534.47397757\n",
      "Validation score: 0.795643\n",
      "Iteration 829, loss = 7922204583.42387867\n",
      "Validation score: 0.795661\n",
      "Iteration 830, loss = 2342279389.25244904\n",
      "Validation score: 0.795699\n",
      "Iteration 831, loss = 799487495.37195587\n",
      "Validation score: 0.795727\n",
      "Iteration 832, loss = 4981587997.05190563\n",
      "Validation score: 0.795750\n",
      "Iteration 833, loss = 738523197.76220787\n",
      "Validation score: 0.795795\n",
      "Iteration 834, loss = 6685022500.97558880\n",
      "Validation score: 0.795799\n",
      "Iteration 835, loss = 184032876.99790952\n",
      "Validation score: 0.795862\n",
      "Iteration 836, loss = 2068305590.49672294\n",
      "Validation score: 0.795874\n",
      "Iteration 837, loss = 817129906.31479585\n",
      "Validation score: 0.795928\n",
      "Iteration 838, loss = 480212918.78545940\n",
      "Validation score: 0.795940\n",
      "Iteration 839, loss = 71899154.52151483\n",
      "Validation score: 0.795995\n",
      "Iteration 840, loss = 430281838.53318298\n",
      "Validation score: 0.795963\n",
      "Iteration 841, loss = 3282335.93530815\n",
      "Validation score: 0.796063\n",
      "Iteration 842, loss = 25710163.74290127\n",
      "Validation score: 0.796064\n",
      "Iteration 843, loss = 14697311.62585426\n",
      "Validation score: 0.796091\n",
      "Iteration 844, loss = 5935425.21378020\n",
      "Validation score: 0.796156\n",
      "Iteration 845, loss = 4848787.06639125\n",
      "Validation score: 0.796096\n",
      "Iteration 846, loss = 548221.81999948\n",
      "Validation score: 0.796208\n",
      "Iteration 847, loss = 2691914.14268410\n",
      "Validation score: 0.796238\n",
      "Iteration 848, loss = 827637.91183092\n",
      "Validation score: 0.796295\n",
      "Iteration 849, loss = 55310.01206537\n",
      "Validation score: 0.796327\n",
      "Iteration 850, loss = 1507010.66309651\n",
      "Validation score: 0.796327\n",
      "Iteration 851, loss = 68503.54035868\n",
      "Validation score: 0.796380\n",
      "Iteration 852, loss = 1607260.32300892\n",
      "Validation score: 0.796430\n",
      "Iteration 853, loss = 6697.40043484\n",
      "Validation score: 0.796441\n",
      "Iteration 854, loss = 715243.64503527\n",
      "Validation score: 0.796464\n",
      "Iteration 855, loss = 15779.92289216\n",
      "Validation score: 0.796533\n",
      "Iteration 856, loss = 18850.48834349\n",
      "Validation score: 0.796525\n",
      "Iteration 857, loss = 33163.53386352\n",
      "Validation score: 0.796578\n",
      "Iteration 858, loss = 8704.65606036\n",
      "Validation score: 0.796632\n",
      "Iteration 859, loss = 5347.00413152\n",
      "Validation score: 0.796578\n",
      "Iteration 860, loss = 4764.69619810\n",
      "Validation score: 0.796690\n",
      "Iteration 861, loss = 279.95761548\n",
      "Validation score: 0.796722\n",
      "Iteration 862, loss = 52.81877901\n",
      "Validation score: 0.796733\n",
      "Iteration 863, loss = 3115.97354428\n",
      "Validation score: 0.796800\n",
      "Iteration 864, loss = 544.21716601\n",
      "Validation score: 0.796818\n",
      "Iteration 865, loss = 200.74706821\n",
      "Validation score: 0.796857\n",
      "Iteration 866, loss = 15.41941663\n",
      "Validation score: 0.796860\n",
      "Iteration 867, loss = 315.96774870\n",
      "Validation score: 0.796923\n",
      "Iteration 868, loss = 17.60571085\n",
      "Validation score: 0.796938\n",
      "Iteration 869, loss = 129.48528150\n",
      "Validation score: 0.796957\n",
      "Iteration 870, loss = 94.09237210\n",
      "Validation score: 0.797027\n",
      "Iteration 871, loss = 9.46286642\n",
      "Validation score: 0.797065\n",
      "Iteration 872, loss = 20.14455999\n",
      "Validation score: 0.797067\n",
      "Iteration 873, loss = 2.28298814\n",
      "Validation score: 0.797095\n",
      "Iteration 874, loss = 101.31210459\n",
      "Validation score: 0.797158\n",
      "Iteration 875, loss = 2.01762238\n",
      "Validation score: 0.797091\n",
      "Iteration 876, loss = 81.27734713\n",
      "Validation score: 0.797211\n",
      "Iteration 877, loss = 65.41430800\n",
      "Validation score: 0.797188\n",
      "Iteration 878, loss = 0.26162984\n",
      "Validation score: 0.797290\n",
      "Iteration 879, loss = 66.17270498\n",
      "Validation score: 0.797268\n",
      "Iteration 880, loss = 1.56923088\n",
      "Validation score: 0.797363\n",
      "Iteration 881, loss = 150.02094858\n",
      "Validation score: 0.797376\n",
      "Iteration 882, loss = 76.71397720\n",
      "Validation score: 0.797407\n",
      "Iteration 883, loss = 17.45974483\n",
      "Validation score: 0.797418\n",
      "Iteration 884, loss = 94.47105672\n",
      "Validation score: 0.797481\n",
      "Iteration 885, loss = 28.62330971\n",
      "Validation score: 0.797464\n",
      "Iteration 886, loss = 0.02107806\n",
      "Validation score: 0.797531\n",
      "Iteration 887, loss = 7.03748741\n",
      "Validation score: 0.797566\n",
      "Iteration 888, loss = 1.80664847\n",
      "Validation score: 0.797512\n",
      "Iteration 889, loss = 0.12357846\n",
      "Validation score: 0.797637\n",
      "Iteration 890, loss = 2.59682231\n",
      "Validation score: 0.797680\n",
      "Iteration 891, loss = 2.09445700\n",
      "Validation score: 0.797718\n",
      "Iteration 892, loss = 0.42385487\n",
      "Validation score: 0.797770\n",
      "Iteration 893, loss = 12.87128414\n",
      "Validation score: 0.797807\n",
      "Iteration 894, loss = 10.63221097\n",
      "Validation score: 0.797838\n",
      "Iteration 895, loss = 8.38921054\n",
      "Validation score: 0.797882\n",
      "Iteration 896, loss = 25.60573802\n",
      "Validation score: 0.797890\n",
      "Iteration 897, loss = 51.19762159\n",
      "Validation score: 0.797957\n",
      "Iteration 898, loss = 10.51300751\n",
      "Validation score: 0.798000\n",
      "Iteration 899, loss = 35.56393290\n",
      "Validation score: 0.797971\n",
      "Iteration 900, loss = 35.67201746\n",
      "Validation score: 0.798062\n",
      "Iteration 901, loss = 0.05383761\n",
      "Validation score: 0.798096\n",
      "Iteration 902, loss = 15.71681769\n",
      "Validation score: 0.798119\n",
      "Iteration 903, loss = 0.31909733\n",
      "Validation score: 0.798133\n",
      "Iteration 904, loss = 14.35261283\n",
      "Validation score: 0.798198\n",
      "Iteration 905, loss = 3.42606494\n",
      "Validation score: 0.798173\n",
      "Iteration 906, loss = 3.33742254\n",
      "Validation score: 0.798239\n",
      "Iteration 907, loss = 0.14903992\n",
      "Validation score: 0.798281\n",
      "Iteration 908, loss = 5.63288590\n",
      "Validation score: 0.798325\n",
      "Iteration 909, loss = 11.22419716\n",
      "Validation score: 0.798302\n",
      "Iteration 910, loss = 9.68758201\n",
      "Validation score: 0.798367\n",
      "Iteration 911, loss = 5.06757216\n",
      "Validation score: 0.798336\n",
      "Iteration 912, loss = 5.00610245\n",
      "Validation score: 0.798419\n",
      "Iteration 913, loss = 0.97478858\n",
      "Validation score: 0.798417\n",
      "Iteration 914, loss = 12.16985505\n",
      "Validation score: 0.798535\n",
      "Iteration 915, loss = 12.05323882\n",
      "Validation score: 0.798553\n",
      "Iteration 916, loss = 4.06751795\n",
      "Validation score: 0.798581\n",
      "Iteration 917, loss = 14.65287339\n",
      "Validation score: 0.798583\n",
      "Iteration 918, loss = 0.91114459\n",
      "Validation score: 0.798672\n",
      "Iteration 919, loss = 0.36441305\n",
      "Validation score: 0.798634\n",
      "Iteration 920, loss = 4.78687498\n",
      "Validation score: 0.798726\n",
      "Iteration 921, loss = 1.75705360\n",
      "Validation score: 0.798762\n",
      "Iteration 922, loss = 6.05788076\n",
      "Validation score: 0.798796\n",
      "Iteration 923, loss = 3.59126029\n",
      "Validation score: 0.798831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 924, loss = 0.25197424\n",
      "Validation score: 0.798832\n",
      "Iteration 925, loss = 0.08205715\n",
      "Validation score: 0.798906\n",
      "Iteration 926, loss = 0.51129512\n",
      "Validation score: 0.798936\n",
      "Iteration 927, loss = 0.09054945\n",
      "Validation score: 0.798975\n",
      "Iteration 928, loss = 0.11803873\n",
      "Validation score: 0.798912\n",
      "Iteration 929, loss = 0.31521919\n",
      "Validation score: 0.799032\n",
      "Iteration 930, loss = 0.00689691\n",
      "Validation score: 0.799072\n",
      "Iteration 931, loss = 1.00322481\n",
      "Validation score: 0.799083\n",
      "Iteration 932, loss = 0.59577737\n",
      "Validation score: 0.799104\n",
      "Iteration 933, loss = 0.17307502\n",
      "Validation score: 0.799178\n",
      "Iteration 934, loss = 0.00723098\n",
      "Validation score: 0.799204\n",
      "Iteration 935, loss = 0.30153200\n",
      "Validation score: 0.799240\n",
      "Iteration 936, loss = 0.75993618\n",
      "Validation score: 0.799228\n",
      "Iteration 937, loss = 0.01931108\n",
      "Validation score: 0.799304\n",
      "Iteration 938, loss = 0.50281919\n",
      "Validation score: 0.799343\n",
      "Iteration 939, loss = 0.13189129\n",
      "Validation score: 0.799374\n",
      "Iteration 940, loss = 0.00584043\n",
      "Validation score: 0.799394\n",
      "Iteration 941, loss = 0.01334798\n",
      "Validation score: 0.799425\n",
      "Iteration 942, loss = 0.00603654\n",
      "Validation score: 0.799486\n",
      "Iteration 943, loss = 0.01186384\n",
      "Validation score: 0.799501\n",
      "Iteration 944, loss = 0.00905214\n",
      "Validation score: 0.799544\n",
      "Iteration 945, loss = 0.00581523\n",
      "Validation score: 0.799552\n",
      "Iteration 946, loss = 0.00604329\n",
      "Validation score: 0.799619\n",
      "Iteration 947, loss = 0.00581293\n",
      "Validation score: 0.799625\n",
      "Iteration 948, loss = 0.00589914\n",
      "Validation score: 0.799672\n",
      "Iteration 949, loss = 0.00582812\n",
      "Validation score: 0.799702\n",
      "Iteration 950, loss = 0.00584595\n",
      "Validation score: 0.799753\n",
      "Iteration 951, loss = 0.00586552\n",
      "Validation score: 0.799782\n",
      "Iteration 952, loss = 0.00583588\n",
      "Validation score: 0.799833\n",
      "Iteration 953, loss = 0.00582787\n",
      "Validation score: 0.799793\n",
      "Iteration 954, loss = 0.00580588\n",
      "Validation score: 0.799842\n",
      "Iteration 955, loss = 0.00623119\n",
      "Validation score: 0.799852\n",
      "Iteration 956, loss = 0.00681260\n",
      "Validation score: 0.799950\n",
      "Iteration 957, loss = 0.00582518\n",
      "Validation score: 0.799939\n",
      "Iteration 958, loss = 0.01401663\n",
      "Validation score: 0.800031\n",
      "Iteration 959, loss = 0.03324649\n",
      "Validation score: 0.800070\n",
      "Iteration 960, loss = 0.00714522\n",
      "Validation score: 0.800084\n",
      "Iteration 961, loss = 0.01087355\n",
      "Validation score: 0.800115\n",
      "Iteration 962, loss = 0.01954867\n",
      "Validation score: 0.800146\n",
      "Iteration 963, loss = 0.00631116\n",
      "Validation score: 0.800140\n",
      "Iteration 964, loss = 0.11932394\n",
      "Validation score: 0.800247\n",
      "Iteration 965, loss = 0.23679028\n",
      "Validation score: 0.800284\n",
      "Iteration 966, loss = 0.05094787\n",
      "Validation score: 0.800311\n",
      "Iteration 967, loss = 0.57533357\n",
      "Validation score: 0.800253\n",
      "Iteration 968, loss = 0.28773812\n",
      "Validation score: 0.800393\n",
      "Iteration 969, loss = 0.00610377\n",
      "Validation score: 0.800412\n",
      "Iteration 970, loss = 0.08326478\n",
      "Validation score: 0.800408\n",
      "Iteration 971, loss = 0.09407277\n",
      "Validation score: 0.800465\n",
      "Iteration 972, loss = 0.04562921\n",
      "Validation score: 0.800526\n",
      "Iteration 973, loss = 0.03048544\n",
      "Validation score: 0.800536\n",
      "Iteration 974, loss = 0.01572096\n",
      "Validation score: 0.800611\n",
      "Iteration 975, loss = 0.03717654\n",
      "Validation score: 0.800635\n",
      "Iteration 976, loss = 0.09095407\n",
      "Validation score: 0.800651\n",
      "Iteration 977, loss = 0.04115093\n",
      "Validation score: 0.800699\n",
      "Iteration 978, loss = 0.00587282\n",
      "Validation score: 0.800710\n",
      "Iteration 979, loss = 0.01207136\n",
      "Validation score: 0.800781\n",
      "Validation score did not improve more than tol=0.000100 for 200 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-4.0810726510435574e+18"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "model = MLPRegressor(solver='adam',  \n",
    "                    hidden_layer_sizes=20, \n",
    "                    random_state=42, \n",
    "                    max_iter=100000, \n",
    "                    verbose=True, \n",
    "                    learning_rate='adaptive',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.0015,\n",
    "                    n_iter_no_change=200,\n",
    "                    tol=0.0001,\n",
    "                    batch_size=5000,\n",
    "                    early_stopping=True)\n",
    "model.out_activation_ = 'sigmoid'\n",
    "model.fit(X, y)\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0810726510435574e+18"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01482987,  0.96753947],\n",
       "       [-0.01682072,  1.13138656]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
